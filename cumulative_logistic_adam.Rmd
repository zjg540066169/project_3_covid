---
title: "cumulative_logistic_adam"
author: "Jungang Zou"
date: "4/17/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(parallel) # one of the core R packages
library(doParallel)
library(foreach)
library(iterators)
```




```{r}
# Use adam optimizer to optimize the mse loss

cumu_logit_adam = function(t, y, parameters = NULL, epoch = NULL, learning_rate = 1e-2, momentum_decay = 0.9, ada_decay = 0.999, tol = 1e-4, print_loss = FALSE, region_name = NULL){
  if (is.null(parameters)) {
     parameters = c(0, 0,0)
  }
 
  # parameters initialize
  a = parameters[1]
  b = parameters[2]
  c = parameters[3]
  output = a / (1 + exp(-b * (t - c)))
  old_loss = sum((output - y)^2) / length(y)
  step = 1
  a_momentum = 0
  b_momentum = 0
  c_momentum = 0
  a_ada = 0
  b_ada = 0
  c_ada = 0
  
  result = list(a, b, c)
  while (TRUE) {
    
    # gradient calculation
    loss_gradient = 2 * (output - y) / length(y)
    e = exp(-b * (t - c))
    a_gradient = sum(loss_gradient * (1 / (1 + e)))
    b_gradient = sum(loss_gradient * (a * e * (t - c) / ((1 + e) ^ 2))) 
    c_gradient = sum(loss_gradient * (-a * e * b / ((1 + e) ^ 2))) 
    
    # momentum udate
    a_momentum = momentum_decay * a_momentum + (1 - momentum_decay) * a_gradient
    # adaGrad update
    a_ada = max(a_ada, ada_decay * a_ada + (1 - ada_decay) * a_gradient^2)
    # parameter update
    a = a - (a_momentum  / (sqrt(a_ada) + tol)) * learning_rate 
    
    
    # momentum udate
    b_momentum = momentum_decay * b_momentum + (1 - momentum_decay) * b_gradient
    # adaGrad update
    b_ada = max(b_ada, ada_decay * b_ada + (1 - ada_decay) * b_gradient^2)
    # parameter update
    b = b - (b_momentum  / (sqrt(b_ada) + tol)) * learning_rate 
    
    
    
    # momentum udate
    c_momentum = momentum_decay * c_momentum + (1 - momentum_decay) * c_gradient
    # adaGrad update
    c_ada = max(c_ada, ada_decay * c_ada + (1 - ada_decay) * c_gradient^2)
    # parameter update
    c = c - (c_momentum / (sqrt(c_ada) + tol)) * learning_rate 
   
    # calculate loss
    output = a / (1 + exp(-b * (t - c)))
    new_loss = sum((output - y)^2) / length(y)
    
    # print loss
    if (print_loss && step %% 100000 == 0)
      print(paste(region_name, " ", step, "steps :", new_loss)) 
    
    # some condition to finish optimization
    if (is.null(new_loss) || is.na(new_loss))
      break
    if (abs(new_loss - old_loss) < tol || new_loss < tol)
      break
    if (!is.null(epoch) && step > epoch)
      break
    
    # save result
    old_loss = new_loss
    step = step + 1
    result = list("a" = a, "b" = b, "c" = c)
  }
  return(result)
  
}
```



```{r}
data = 
  read_csv("covid19-1.csv") %>% 
  #select(-Id) %>% 
  janitor::clean_names() %>% 
  mutate(date = as.Date.character(date, "%m/%d/%y")) %>% 
  group_by(country_region, date) %>% 
  mutate(confirmed_cases = sum(confirmed_cases), fatalities = sum(fatalities)) %>% 
  ungroup() %>% 
  select(-id, -province_state, -fatalities, -lat, -long) %>% 
  distinct()
  
  
  
first_infection = 
  data %>% 
  filter(confirmed_cases != 0) %>% 
  group_by(country_region) %>%
  summarise(first = min(date)) %>% 
  ungroup()
  
data = 
  data %>% 
  left_join(first_infection, by = "country_region") %>% 
  
  mutate(date = date - first + 1) %>% 
  mutate(date = as.integer(date)) %>% 
  select(-first)

data$date[data$date < 0] = 0

data = distinct(data)
parameters = tibble("region_name", "a", "b", "c")


### single thread ####
for (region in unique(data$`country_region`)) {
  #if (region != "China")
  #  next
  region_data = filter(data, data$'country_region' == region)
  
  result = cumu_logit_adam(region_data$date, region_data$confirmed_cases, region_name = region, print_loss = TRUE)
  parameters = rbind(parameters, c(region, result[[1]], result[[2]], result[[3]]))
  #break
}

parameters = parameters[-1,]


#### parallel #####
#nCores <- 4  # to set manually
#registerDoParallel(nCores) 

#out <- foreach(i = 1:length(unique(data$`country_region`)), .combine = rbind) %dopar% {
#  cat('Starting ', i, 'th job.\n', sep = '')
#  region = unique(data$`country_region`)[i]
#  region_data = filter(data, data$'country_region' == region)
  
#  result = cumu_logit_adam(region_data$date, region_data$confirmed_cases, region_name = region, print_loss = FALSE)
#  result$region_name = region
#  cat('Finishing ', i, 'th job.\n', sep = '')
#  result # this will become part of the out object
#}
#parameters = out



# draw graph
a = result[[1]]
b = result[[2]]
c_ = result[[3]]
plot(seq(-1, 56), a / (1 + exp(-b * (seq(-1, 56) - c_))))
```
